{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "from mnist_deep import deepnn\n",
    "import numpy as np\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal mnist model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.08\n",
      "step 100, training accuracy 0.82\n",
      "step 200, training accuracy 0.94\n",
      "step 300, training accuracy 0.94\n",
      "step 400, training accuracy 0.94\n",
      "step 500, training accuracy 0.92\n",
      "step 600, training accuracy 0.94\n",
      "step 700, training accuracy 0.96\n",
      "step 800, training accuracy 0.96\n",
      "step 900, training accuracy 0.96\n",
      "test accuracy 0.9615\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.int32, [None, 10])\n",
    "y_conv, keep_prob = deepnn(x)\n",
    "with tf.name_scope('loss'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_conv)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "with tf.name_scope('adam_optimizer'):\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
    "    correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "accuracy = tf.reduce_mean(correct_prediction)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "      batch = mnist.train.next_batch(50)\n",
    "      if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x: batch[0], y: batch[1], keep_prob: 1.0})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "      train_step.run(feed_dict={x: batch[0], y: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "        x: mnist.test.images, y: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist_with_outlier:\n",
    "    def __init__(self, mnist, no_outlier_numbers, outlier_numbers, outlier_ratio=0.3):\n",
    "        self.mnist = mnist\n",
    "        self.no_outlier_numbers = no_outlier_numbers\n",
    "        self.outlier_numbers = outlier_numbers\n",
    "        self.outlier_ratio = outlier_ratio\n",
    "        self.train_images, self.train_labels = self.add_outlier(self.mnist.train.images, self.mnist.train.labels)\n",
    "        self.test_images, self.test_labels = self.extract_test(self.mnist.test.images, self.mnist.test.labels)\n",
    "        self._index_in_epoch = 0\n",
    "        self._epochs_completed = 0\n",
    "        self._num_examples = self.train_images.shape[0]\n",
    "    \n",
    "    def extract_test(self, images, labels):\n",
    "        extracted_images, extracted_labels = self.extract_number(images, labels)\n",
    "        extracted_labels = self.dense_to_one_hot(extracted_labels, len(self.no_outlier_numbers))\n",
    "        return extracted_images, extracted_labels\n",
    "    \n",
    "    def extract_number(self, images, labels):\n",
    "        mixed_images = np.array([])\n",
    "        mixed_labels = np.array([])\n",
    "        label_numbers = np.where(labels == 1)[1]\n",
    "        for i in self.no_outlier_numbers:\n",
    "            i_positions = np.where(label_numbers == i)[0].reshape(-1)\n",
    "            if mixed_images.shape[0] == 0:\n",
    "                mixed_images = images[i_positions]\n",
    "            else:\n",
    "                mixed_images = np.concatenate((mixed_images ,images[i_positions]))\n",
    "            mixed_labels = np.concatenate((mixed_labels, np.array([i] * len(i_positions))))\n",
    "        return mixed_images, mixed_labels\n",
    "        \n",
    "    def add_outlier(self, images, labels):\n",
    "        mixed_images, mixed_labels = self.extract_number(images, labels)\n",
    "        if self.outlier_ratio > 0:\n",
    "            outlier_num = int(mixed_images.shape[0] * self.outlier_ratio)\n",
    "            outlier_images = np.array([])\n",
    "            label_numbers = np.where(labels == 1)[1]\n",
    "            for j in self.outlier_numbers:\n",
    "                j_positions = np.where(label_numbers == j)[0].reshape(-1)\n",
    "                if outlier_images.shape[0] == 0:\n",
    "                    outlier_images = images[j_positions]\n",
    "                else:\n",
    "                    outlier_images = np.concatenate((outlier_images ,images[j_positions]))\n",
    "\n",
    "            outlier_images_samples = outlier_images[np.random.choice(len(outlier_images), outlier_num, replace=False)]\n",
    "            outlier_labels_samples = np.random.choice(self.no_outlier_numbers, outlier_num, replace=True)\n",
    "\n",
    "            mixed_images = np.concatenate((mixed_images, outlier_images_samples))\n",
    "            mixed_labels = np.concatenate((mixed_labels, outlier_labels_samples))\n",
    "\n",
    "            idx = np.random.permutation(len(mixed_labels))\n",
    "            mixed_images, mixed_labels = mixed_images[idx], mixed_labels[idx]\n",
    "        \n",
    "        return mixed_images, self.dense_to_one_hot(mixed_labels, len(self.no_outlier_numbers))\n",
    "    \n",
    "    def dense_to_one_hot(self, labels, num_classes):\n",
    "        labels_dense = np.array([self.no_outlier_numbers.index(i) for i in labels])\n",
    "        num_labels = labels_dense.shape[0]\n",
    "        index_offset = np.arange(num_labels) * num_classes\n",
    "        labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "        labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "        return labels_one_hot\n",
    "     \n",
    "    def next_batch(self, batch_size, shuffle=True):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        # Go to the next epoch\n",
    "        if start + batch_size > self._num_examples:\n",
    "          # Finished epoch\n",
    "          self._epochs_completed += 1\n",
    "          # Get the rest examples in this epoch\n",
    "          rest_num_examples = self._num_examples - start\n",
    "          images_rest_part = self.train_images[start:self._num_examples]\n",
    "          labels_rest_part = self.train_labels[start:self._num_examples]\n",
    "          # Shuffle the data\n",
    "          if shuffle:\n",
    "            perm = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            self.train_images = self.train_images[perm]\n",
    "            self.train_labels = self.train_labels[perm]\n",
    "          # Start next epoch\n",
    "          start = 0\n",
    "          self._index_in_epoch = batch_size - rest_num_examples\n",
    "          end = self._index_in_epoch\n",
    "          images_new_part = self.train_images[start:end]\n",
    "          labels_new_part = self.train_labels[start:end]\n",
    "          return np.concatenate((images_rest_part, images_new_part), axis=0) , np.concatenate((labels_rest_part, labels_new_part), axis=0)\n",
    "        else:\n",
    "          self._index_in_epoch += batch_size\n",
    "          end = self._index_in_epoch\n",
    "          return self.train_images[start:end], self.train_labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use cnn to classify number 6,7 while adding outliers 2 randomly labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14471, 784)\n",
      "(14471, 2)\n",
      "(1986, 784)\n",
      "(1986, 2)\n"
     ]
    }
   ],
   "source": [
    "mnist_outlier = mnist_with_outlier(mnist, [6,7], [2])\n",
    "print(mnist_outlier.train_images.shape)\n",
    "print(mnist_outlier.train_labels.shape)\n",
    "print(mnist_outlier.test_images.shape)\n",
    "print(mnist_outlier.test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.44\n",
      "step 100, training accuracy 0.86\n",
      "step 200, training accuracy 0.9\n",
      "step 300, training accuracy 0.9\n",
      "step 400, training accuracy 0.82\n",
      "step 500, training accuracy 0.92\n",
      "step 600, training accuracy 0.88\n",
      "step 700, training accuracy 0.84\n",
      "step 800, training accuracy 0.88\n",
      "step 900, training accuracy 0.88\n",
      "test accuracy 0.998993\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.int32, [None, 2])\n",
    "y_conv, keep_prob = deepnn(x)\n",
    "with tf.name_scope('loss'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_conv)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "with tf.name_scope('adam_optimizer'):\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
    "    correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "accuracy = tf.reduce_mean(correct_prediction)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "      batch = mnist_outlier.next_batch(50)\n",
    "      if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x: batch[0], y: batch[1], keep_prob: 1.0})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "      train_step.run(feed_dict={x: batch[0], y: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "        x: mnist_outlier.test_images, y: mnist_outlier.test_labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11132, 784)\n",
      "(11132, 2)\n",
      "(1986, 784)\n",
      "(1986, 2)\n"
     ]
    }
   ],
   "source": [
    "mnist_simple = mnist_with_outlier(mnist, [6,7], [], outlier_ratio=0)\n",
    "print(mnist_simple.train_images.shape)\n",
    "print(mnist_simple.train_labels.shape)\n",
    "print(mnist_simple.test_images.shape)\n",
    "print(mnist_simple.test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use cnn to classify number 6,7 while not adding outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0\n",
      "step 100, training accuracy 1\n",
      "step 200, training accuracy 1\n",
      "step 300, training accuracy 1\n",
      "step 400, training accuracy 0.98\n",
      "step 500, training accuracy 1\n",
      "step 600, training accuracy 1\n",
      "step 700, training accuracy 1\n",
      "step 800, training accuracy 1\n",
      "step 900, training accuracy 1\n",
      "test accuracy 0.998993\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.int32, [None, 2])\n",
    "y_conv, keep_prob = deepnn(x)\n",
    "with tf.name_scope('loss'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_conv)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "with tf.name_scope('adam_optimizer'):\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
    "    correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "accuracy = tf.reduce_mean(correct_prediction)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "      batch = mnist_simple.next_batch(50)\n",
    "      if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x: batch[0], y: batch[1], keep_prob: 1.0})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "      train_step.run(feed_dict={x: batch[0], y: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "        x: mnist_simple.test_images, y: mnist_simple.test_labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14471, 784)\n",
      "(14471, 2)\n",
      "(1986, 784)\n",
      "(1986, 2)\n"
     ]
    }
   ],
   "source": [
    "mnist_outlier_all = mnist_with_outlier(mnist, [6,7], [0,1,2,3,4,5,8,9], outlier_ratio=0.3)\n",
    "print(mnist_outlier_all.train_images.shape)\n",
    "print(mnist_outlier_all.train_labels.shape)\n",
    "print(mnist_outlier_all.test_images.shape)\n",
    "print(mnist_outlier_all.test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use cnn to classify number 6,7 while adding other numbers as outliers randomly labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.56\n",
      "step 100, training accuracy 0.88\n",
      "step 200, training accuracy 0.88\n",
      "step 300, training accuracy 0.82\n",
      "step 400, training accuracy 0.8\n",
      "step 500, training accuracy 0.9\n",
      "step 600, training accuracy 0.9\n",
      "step 700, training accuracy 0.86\n",
      "step 800, training accuracy 0.84\n",
      "step 900, training accuracy 0.9\n",
      "test accuracy 0.998489\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.int32, [None, 2])\n",
    "y_conv, keep_prob = deepnn(x)\n",
    "with tf.name_scope('loss'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_conv)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "with tf.name_scope('adam_optimizer'):\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
    "    correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "accuracy = tf.reduce_mean(correct_prediction)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "      batch = mnist_outlier_all.next_batch(50)\n",
    "      if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x: batch[0], y: batch[1], keep_prob: 1.0})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "      train_step.run(feed_dict={x: batch[0], y: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "        x: mnist_outlier_all.test_images, y: mnist_outlier_all.test_labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
